"""
–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π —á–∞—Ç-–±–æ—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –£–≥–æ–ª–æ–≤–Ω–æ–º—É –∫–æ–¥–µ–∫—Å—É (C√≥digo Penal)

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞,
–∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –£–≥–æ–ª–æ–≤–Ω–æ–º—É –∫–æ–¥–µ–∫—Å—É, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω–¥–µ–∫—Å—ã FAISS.
"""

import json
import os
import re
from typing import List, Dict, Any, Optional, Tuple
from sentence_transformers import SentenceTransformer
import faiss
from search import (
    search_similar_chunks, 
    search_by_article_number, 
    expand_chunks_with_neighbors,
    extract_intent,
    calculate_relevance_score
)

class LegalAssistant:
    """
    –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –£–≥–æ–ª–æ–≤–Ω–æ–º—É –∫–æ–¥–µ–∫—Å—É
    """
    
    def __init__(
        self, 
        chunks_file: str = "output/penal_code_chunks.json",
        index_path: str = "output/penal_code.index",
        model_name: str = "all-MiniLM-L6-v2"
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.
        
        Args:
            chunks_file (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —á–∞–Ω–∫–∞–º–∏ —Ç–µ–∫—Å—Ç–∞
            index_path (str): –ü—É—Ç—å –∫ FAISS –∏–Ω–¥–µ–∫—Å—É
            model_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        """
        # –ó–∞–≥—Ä—É–∑–∫–∞ —á–∞–Ω–∫–æ–≤
        if not os.path.exists(chunks_file):
            alternative_path = "penal_code_chunks.json"
            if os.path.exists(alternative_path):
                chunks_file = alternative_path
            else:
                raise FileNotFoundError(f"–§–∞–π–ª —Å —á–∞–Ω–∫–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {chunks_file}")
        
        with open(chunks_file, "r", encoding="utf-8") as f:
            self.chunks = json.load(f)
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–∞
        if not os.path.exists(index_path):
            raise FileNotFoundError(f"–ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω: {index_path}")
            
        self.index_path = index_path
        self.model_name = model_name
        
        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
        self.query_cache = {}
        
        # –°–ª–æ–≤–∞—Ä—å —Ç–∏–ø–∏—á–Ω—ã—Ö —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –∏—Ö –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–æ–∫ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞
        self.legal_questions = {
            "—Å—Ä–æ–∫ –¥–∞–≤–Ω–æ—Å—Ç–∏": [
                "plazo de prescripci√≥n", 
                "prescripci√≥n de delito",
                "tiempo para procesar"
            ],
            "–Ω–∞–∫–∞–∑–∞–Ω–∏–µ –∑–∞": [
                "pena por",
                "sanci√≥n aplicable",
                "castigo establecido"
            ],
            "—á—Ç–æ —Å—á–∏—Ç–∞–µ—Ç—Å—è": [
                "definici√≥n de",
                "concepto legal de",
                "qu√© constituye"
            ]
        }
        
        print(f"–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.chunks)} —á–∞–Ω–∫–æ–≤ —Ç–µ–∫—Å—Ç–∞.")
    
    def answer_question(self, question: str) -> str:
        """
        –û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –¥–∞–Ω–Ω—ã–µ –£–≥–æ–ª–æ–≤–Ω–æ–≥–æ –∫–æ–¥–µ–∫—Å–∞.
        
        Args:
            question (str): –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            str: –û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å —Ü–∏—Ç–∞—Ç–∞–º–∏ –∏–∑ –£–≥–æ–ª–æ–≤–Ω–æ–≥–æ –∫–æ–¥–µ–∫—Å–∞
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –∑–∞–ø—Ä–æ—Å–æ–≤
        if question in self.query_cache:
            return self.query_cache[question]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
        intent, param = extract_intent(question)
        
        # –ü–æ–∏—Å–∫ –ø–æ —Å—Ç–∞—Ç—å–µ
        if intent == "article_search" and param:
            results = search_by_article_number(param, self.chunks)
            if not results:
                # –ï—Å–ª–∏ —Å—Ç–∞—Ç—å—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–±—É–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
                results = search_similar_chunks(
                    f"Art√≠culo {param}", 
                    self.chunks, 
                    self.index_path, 
                    self.model_name,
                    top_k=3
                )
        else:
            # –î–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –æ —Å—Ä–æ–∫–∞—Ö –¥–∞–≤–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∫–∏
            if intent == "prescription_search":
                expanded_queries = self._expand_legal_query(question, "—Å—Ä–æ–∫ –¥–∞–≤–Ω–æ—Å—Ç–∏")
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
                all_results = []
                for query in expanded_queries:
                    query_results = search_similar_chunks(
                        query, 
                        self.chunks, 
                        self.index_path,
                        self.model_name,
                        top_k=2
                    )
                    all_results.extend(query_results)
                
                # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                seen_indices = set()
                results = []
                for res in sorted(all_results, key=lambda x: x.get("distance", float('inf'))):
                    idx = (res["libro"], res["titulo"], res["capitulo"], res["chunk_index"])
                    if idx not in seen_indices:
                        seen_indices.add(idx)
                        results.append(res)
                
                results = results[:3]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç—Ä–µ–º—è —Å–∞–º—ã–º–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            else:
                # –û–±—ã—á–Ω—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
                results = search_similar_chunks(
                    question, 
                    self.chunks, 
                    self.index_path,
                    self.model_name,
                    top_k=3
                )
        
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —Ä–∞—Å—à–∏—Ä—è–µ–º –∏—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        if results:
            expanded_results = expand_chunks_with_neighbors(results, self.chunks, window=1)
            answer = self._format_answer(question, expanded_results)
        else:
            answer = "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –Ω–∞—à—ë–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –≤ –£–≥–æ–ª–æ–≤–Ω–æ–º –∫–æ–¥–µ–∫—Å–µ. " + \
                     "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–Ω–∞—á–µ –∏–ª–∏ —É—Ç–æ—á–Ω–∏—Ç–µ, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç."
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        self.query_cache[question] = answer
        
        return answer
    
    def _expand_legal_query(self, question: str, query_type: str) -> List[str]:
        """
        –†–∞—Å—à–∏—Ä—è–µ—Ç –∑–∞–ø—Ä–æ—Å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞–º–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞.
        
        Args:
            question (str): –ò—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å
            query_type (str): –¢–∏–ø –≤–æ–ø—Ä–æ—Å–∞ (—Å—Ä–æ–∫ –¥–∞–≤–Ω–æ—Å—Ç–∏, –Ω–∞–∫–∞–∑–∞–Ω–∏–µ –∏ —Ç.–¥.)
            
        Returns:
            List[str]: –°–ø–∏—Å–æ–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        """
        expanded_queries = [question]
        
        if query_type in self.legal_questions:
            for phrase in self.legal_questions[query_type]:
                expanded_queries.append(f"{question} {phrase}")
        
        return expanded_queries
    
    def _format_answer(self, question: str, results: List[Dict]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –£–≥–æ–ª–æ–≤–Ω–æ–≥–æ –∫–æ–¥–µ–∫—Å–∞.
        
        Args:
            question (str): –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            results (List[Dict]): –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
            
        Returns:
            str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å —Ü–∏—Ç–∞—Ç–∞–º–∏
        """
        answer_parts = []
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç–≤–µ—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –≤–æ–ø—Ä–æ—Å–∞
        intent, param = extract_intent(question)
        
        if intent == "article_search":
            answer_parts.append(f"üìö **–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –æ —Å—Ç–∞—Ç—å–µ {param} –£–≥–æ–ª–æ–≤–Ω–æ–≥–æ –∫–æ–¥–µ–∫—Å–∞:**\n")
        elif intent == "prescription_search":
            answer_parts.append("üìö **–ü–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É –æ —Å—Ä–æ–∫–∞—Ö –¥–∞–≤–Ω–æ—Å—Ç–∏:**\n")
        else:
            answer_parts.append("üìö **–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É —è –Ω–∞—à–µ–ª —Å–ª–µ–¥—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –£–≥–æ–ª–æ–≤–Ω–æ–º –∫–æ–¥–µ–∫—Å–µ:**\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∞–º—ã–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
        seen_texts = set()
        relevance_threshold = 20.0  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –æ—Ç–≤–µ—Ç
        
        for i, chunk in enumerate(results[:5], 1):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø—è—Ç—å—é —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º–∏
            text = self._clean_text_for_answer(chunk["text"])
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Ç–µ–∫—Å—Ç–∞
            if text in seen_texts:
                continue
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
            relevance = chunk.get("relevance_score", 0)
            if relevance == 0 and "distance" in chunk:
                relevance = calculate_relevance_score(chunk["distance"])
                
            if relevance < relevance_threshold and i > 1:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ)
                
            seen_texts.add(text)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞
            section_name = []
            if chunk["libro"]:
                section_name.append(chunk["libro"])
            if chunk["titulo"] and chunk["titulo"] != chunk["libro"]:
                section_name.append(chunk["titulo"])
            if chunk["capitulo"] and chunk["capitulo"] not in [chunk["libro"], chunk["titulo"]]:
                section_name.append(chunk["capitulo"])
                
            section_str = " > ".join(section_name)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—Ç–≤–µ—Ç
            context_label = " (–∫–æ–Ω—Ç–µ–∫—Å—Ç)" if chunk.get("is_context") else ""
            answer_parts.append(f"### {section_str}{context_label}\n")
            answer_parts.append(f"**–°—Ç–∞—Ç—å–∏: {', '.join(chunk['article_numbers'])}**\n")
            answer_parts.append(f"{text}\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–∫–ª—é—á–µ–Ω–∏–µ
        answer_parts.append("\n---\n")
        answer_parts.append("–≠—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –£–≥–æ–ª–æ–≤–Ω–æ–≥–æ –∫–æ–¥–µ–∫—Å–∞, –∫–æ—Ç–æ—Ä–∞—è –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É. ")
        answer_parts.append("–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ —è –º–æ–≥—É —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç –∑–∞–∫–æ–Ω–∞, –Ω–æ –Ω–µ –¥–∞–≤–∞—Ç—å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π. ")
        answer_parts.append("–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —é—Ä–∏—Å—Ç—É.")
        
        return "\n".join(answer_parts)
    
    def _clean_text_for_answer(self, text: str) -> str:
        """
        –û—á–∏—â–∞–µ—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞.
        
        Args:
            text (str): –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            str: –û—á–∏—â–µ–Ω–Ω—ã–π –∏ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        text = re.sub(r'\s+', ' ', text).strip()
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –≤ –Ω—É–∂–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
        text = re.sub(r'(\d+\.)\s+', r'\n\1 ', text)
        text = re.sub(r'(Art√≠culo \d+\.?)\s+', r'\n\1 ', text)
        
        return text

if __name__ == "__main__":
    print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞...")
    assistant = LegalAssistant()
    
    print("\nü§ñ –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –£–≥–æ–ª–æ–≤–Ω–æ–º—É –∫–æ–¥–µ–∫—Å—É")
    print("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ –∑–∞–∫–æ–Ω–µ, —Å—Ç–∞—Ç—å–µ –∏–ª–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏.")
    
    while True:
        question = input("\n–í–∞—à –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞): ")
        
        if question.lower() in ['q', 'quit', 'exit']:
            break
            
        answer = assistant.answer_question(question)
        print("\n" + answer)